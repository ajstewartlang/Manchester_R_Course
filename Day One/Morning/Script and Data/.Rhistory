library (dplyr) #data wrangling package
library (tidyr) #data wrangling package
library (ggplot2) #needed for ggplot
library (yarrr) #needed for pirate plots
library (viridis) #needed for heat map plotting
library (MASS) #needed for sample from normal distribution
library (Hmisc) #needed for correlation
library (psych) #needed for describeBy to generate descriptives
library (emmeans) #needed for pairwise comparisons
library (DescTools) #needed for effect size calculations
library (afex) #needed for factorial ANOVA (Type III SS and contrast coding)
library (car) #needed for Durbin Watson test
library (olsrr) #needed for adjusted R squared model fit improvement
library (leaps) #helps visualise multiple regression model fit
library (readr) #needed to read in data files
library (stargazer) #nice regression tables
library (multilevel) #needed for Sobel test to interpret mediation via Baron and Kenny method
library (mediation) #needed to use the mediate funciton
library (rtweet) #needed to scrape via Twitter Developer API
library (leaflet) #needed to geo plot Twitter data
library (maps) #needed to geo plot Twitter data
install.packages("viridis")
install.packages("HMisc")
install.packages("Hmisc")
install.packages("DescTools")
install.packages("afex")
install.packages("car")
install.packages("olsrr")
install.packages("leaps")
install.packages("stargazer")
install.packages("multilevel")
install.packages("mediation")
install.packages("rtweet")
install.packages("leaflet")
install.packages("maps")
library (dplyr) #data wrangling package
library (tidyr) #data wrangling package
library (ggplot2) #needed for ggplot
library (yarrr) #needed for pirate plots
library (viridis) #needed for heat map plotting
library (MASS) #needed for sample from normal distribution
library (Hmisc) #needed for correlation
library (psych) #needed for describeBy to generate descriptives
library (emmeans) #needed for pairwise comparisons
library (DescTools) #needed for effect size calculations
library (afex) #needed for factorial ANOVA (Type III SS and contrast coding)
library (car) #needed for Durbin Watson test
library (olsrr) #needed for adjusted R squared model fit improvement
library (leaps) #helps visualise multiple regression model fit
library (readr) #needed to read in data files
library (stargazer) #nice regression tables
library (multilevel) #needed for Sobel test to interpret mediation via Baron and Kenny method
library (mediation) #needed to use the mediate funciton
library (rtweet) #needed to scrape via Twitter Developer API
library (leaflet) #needed to geo plot Twitter data
library (maps) #needed to geo plot Twitter data
set.seed (1234)
ID <- seq (1:10000)
WM <- as.integer(rnorm (10000, mean=50, sd=5))
IQ <- as.integer(rnorm (10000, mean=100, sd=15))
Comp <- as.integer(rnorm (10000, mean=20, sd=2))
data <- data.frame (ID, WM, IQ, Comp)
colnames(data) = c("ID", "WM", "IQ", "Comp")
#Create data for 48 participants (all present in data) taking part in an experiment
ID <- sample (ID, 48)
Simple <- as.integer(rnorm (48, mean=2000, sd=140))
Complex <- as.integer(rnorm (48, mean=2400, sd=160))
dataRT <- data.frame (ID, Simple, Complex)
colnames(dataRT) = c("ID", "Simple Sentence", "Complex Sentence")
dataRT_all <- inner_join (data, dataRT, by=(c("ID")))
data_transformed <- mutate (dataRT_all, log_Simple=log (dataRT_all$`Simple Sentence`), log_Complex=log (dataRT$`Complex Sentence`))
index <- data_transformed$ID!=1191
index
filtered_data <- data_transformed[index,]
data_long <- gather (dataRT, "Condition", "RT", c("Simple Sentence", "Complex Sentence"))
View (data_long)
rt <- search_tweets(
"Opeth", n = 1000, include_rts = FALSE, retryonratelimit = TRUE
)
rt1 <- separate(data = rt, col = created_at, into = c("date", "time"), sep = " ")
rt1 <- rt1[!is.na(rt1$date),]
rt1$date <- as.factor (rt1$date)
data <- rt1
ggplot (data, aes (x=date)) + geom_bar(fill="blue") + scale_y_continuous(expand = c(0,0),
limits = c(0,500)) +
labs(x="Day", y="Number of Tweets") + ggtitle ("Tweets Mentioning Opeth") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
#plotting Tweets on map
mymap <- lat_lng(rt)
m <- leaflet(mymap) %>% addTiles()
m %>% addCircles(lng = ~lng, lat = ~lat, weight = 8, radius = 40, color = "#fb3004", stroke = TRUE, fillOpacity = 0.8)
##get
DV <- read_csv("DV.csv", col_types = cols(Context = col_factor(levels = c("Positive",
"Negative")), Sentence = col_factor(levels = c("Positive",
DV <- read_csv("DV.csv", col_types = cols(Context = col_factor(levels = c("Positive",
"Negative")), Sentence = col_factor(levels = c("Positive",
"Negative"))))
DV
model <- aov_4 (RT ~ Sentence*Context + (1+Sentence*Context |Subject), data=DV, na.rm=TRUE)
anova (model)
regression <- read_csv("regression2.csv")
model.full <- lm (Points ~ Investment + Car_performance + Age + Media_coverage, data=regression)
model.null <- lm (Points ~ 1, data=regression)
anova (model.full, model.null)
summary (model.full)
